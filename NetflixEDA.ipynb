{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "896ece98-8fb0-4d8b-918d-21c59927ad27",
   "metadata": {},
   "source": [
    "# Netflix Exploratory Data Analysis\n",
    "---\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "This project was developed as a **personal learning exercise** to strengthen my skills in **data analysis**, with a particular focus on **Exploratory Data Analysis (EDA)**. The goal is twofold:  \n",
    "1. To practice the process of **cleaning, exploring, and visualizing real-world data**.  \n",
    "2. To extract **meaningful insights** about the structure and trends of Netflix content.  \n",
    "\n",
    "The dataset used in this analysis comes from [Kaggle’s *Netflix Movies and TV Shows* dataset](https://www.kaggle.com/datasets/shivamb/netflix-shows), which contains information such as titles, release years, countries, genres, ratings, and durations. This rich dataset provides an excellent opportunity to explore patterns in Netflix’s catalog and to demonstrate the application of various Python tools for data analysis.\n",
    "\n",
    "\n",
    "#### 1.1 Before starting\n",
    "\n",
    "Before diving into the dataset, it is essential to import the core Python libraries that will support the analysis. These libraries provide the necessary tools for data manipulation, numerical computations, and visualization, forming the foundation of most modern data analysis workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0563257f-9ce8-4248-9cad-37e8fd4c974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1bb23a-7526-4c3a-9060-bcc756fa35ae",
   "metadata": {},
   "source": [
    "After setting up the environment, the next step is to **load the dataset** into a Pandas DataFrame. This will allow us to efficiently manipulate, clean, and explore the data throughout the analysis.\n",
    "\n",
    "The dataset is stored in the local `./dataset` folder as a CSV file. We begin by reading it into a DataFrame and inspecting its basic structure to better understand its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9bbd6fc-8e6d-43a9-b18c-57cf997d3dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8807, 12)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/netflix_titles.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db39ae2-7908-43f9-990d-36620ba1807f",
   "metadata": {},
   "source": [
    "We can confirm that the data is correctly imported. Now it is time to start doing the data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9924bcd-b099-4690-89a1-a78ed01422be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
